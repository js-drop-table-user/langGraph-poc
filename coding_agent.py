"""
ë©€í‹° ì—ì´ì „íŠ¸ ì½”ë”© ì‹œìŠ¤í…œ (Supervisor Pattern + Custom ReAct Loop)
LangGraph + Ollama + Tools + Persistence
Refactored to Standard LangGraph Structure & Modular Runtime
"""

import functools
import os
import re
from typing import Annotated, List, Sequence, TypedDict

from langchain_core.messages import AIMessage, BaseMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import START, StateGraph
from langgraph.graph.message import add_messages

from config import AgentConfig, OllamaConfig
from core.agent_runtime import run_react_agent
from core.llm_factory import get_llm
from tools import CODER_TOOLS, PLANNER_TOOLS, REVIEWER_TOOLS

# SQLite DB ê²½ë¡œ
DB_PATH = os.path.join(OllamaConfig.WORKSPACE_DIR, "agent_memory.sqlite")


# =============================================================================
# State ì •ì˜
# =============================================================================
class AgentState(TypedDict):
    """ë©€í‹° ì—ì´ì „íŠ¸ í†µí•© ìƒíƒœ"""

    messages: Annotated[Sequence[BaseMessage], add_messages]
    next: str  # ë‹¤ìŒì— ì‹¤í–‰í•  ì—ì´ì „íŠ¸ ì´ë¦„


# =============================================================================
# Custom Agent Node (Internal ReAct Loop)
# =============================================================================
def custom_agent_node(state: AgentState, name: str, system_prompt: str, tools: List):
    """
    ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ë…¸ë“œ Wrapper.
    Core Runtimeì„ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ Graph State í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    history = state["messages"]

    # Core Runtime ì‹¤í–‰ (Modularized)
    final_response = run_react_agent(name, system_prompt, tools, history)

    # ê²°ê³¼ ë°˜í™˜ (HumanMessageë¡œ í¬ìž¥í•˜ì—¬ Supervisorì—ê²Œ ì „ë‹¬)
    return {"messages": [HumanMessage(content=final_response, name=name)]}


# =============================================================================
# Supervisor (Orchestrator)
# =============================================================================
def supervisor_node(state: AgentState):
    """Supervisor logic: ë‹¤ìŒ ì—ì´ì „íŠ¸ë¥¼ ê²°ì •"""
    llm = get_llm()
    conf = AgentConfig.SUPERVISOR_CONFIG

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", conf["prompt"]),
            MessagesPlaceholder(variable_name="messages"),
            (
                "system",
                "Given the conversation above, who should act next? "
                "Select one of: {options}. "
                "Return ONLY the name of the next worker, or 'FINISH' if done.",
            ),
        ]
    ).partial(options=str(conf["options"]), members=", ".join(conf["members"]))

    chain = prompt | llm
    response = chain.invoke(state)
    decision = response.content.strip()

    # ì •ê·œì‹ ê¸°ë°˜ ë§¤ì¹­ (ê²¬ê³ ì„± ê°•í™”)
    next_agent = "FINISH"  # Default fallback
    found_agents = []

    for option in conf["options"]:
        # ë‹¨ì–´ ê²½ê³„(\b)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ë§¤ì¹­ (Case-insensitive)
        if re.search(rf"\b{option}\b", decision, re.IGNORECASE):
            found_agents.append(option)

    # ì—¬ëŸ¬ ê°œê°€ ë§¤ì¹­ë˜ë©´ ê°€ìž¥ ë§ˆì§€ë§‰ì— ì–¸ê¸‰ëœ ê²ƒ, í˜¹ì€ ëª…ì‹œì  ìš°ì„ ìˆœìœ„ ì ìš©
    # ì—¬ê¸°ì„œëŠ” ë°œê²¬ëœ ê²ƒ ì¤‘ ë§ˆì§€ë§‰ ì˜µì…˜ì„ ì„ íƒ (ë¬¸ìž¥ ëì— ë³´í†µ ê²°ë¡ ì´ ì˜¤ë¯€ë¡œ)
    if found_agents:
        next_agent = found_agents[-1]

    print(f"[Supervisor] Raw: {decision!r} -> Next: {next_agent}")

    return {
        "messages": [AIMessage(content=decision, name="Supervisor")],
        "next": next_agent,
    }


# =============================================================================
# Graph Construction
# =============================================================================
def create_graph():
    workflow = StateGraph(AgentState)

    # Supervisor Node
    workflow.add_node("Supervisor", supervisor_node)

    # Worker Nodes Check
    agents = [
        ("Planner", PLANNER_TOOLS, AgentConfig.PROMPTS["Planner"]),
        ("Coder", CODER_TOOLS, AgentConfig.PROMPTS["Coder"]),
        ("Reviewer", REVIEWER_TOOLS, AgentConfig.PROMPTS["Reviewer"]),
    ]

    for name, tools, prompt in agents:
        workflow.add_node(
            name,
            functools.partial(
                custom_agent_node, name=name, system_prompt=prompt, tools=tools
            ),
        )
        # ëª¨ë“  WorkerëŠ” ìž‘ì—… í›„ Supervisorë¡œ ë³µê·€
        workflow.add_edge(name, "Supervisor")

    # Start Edge
    workflow.add_edge(START, "Supervisor")

    # Conditional Edges from Supervisor
    # map: next_agent ì´ë¦„ ê·¸ëŒ€ë¡œ ë…¸ë“œë¡œ ì´ë™. FINISHë©´ ì¢…ë£Œ.
    workflow.add_conditional_edges("Supervisor", lambda x: x["next"])

    return workflow


# =============================================================================
# Main
# =============================================================================
def main():
    print("=" * 60)
    print("ðŸ¤– Multi-Agent System (Standardized LangGraph v2)")
    print("=" * 60)

    workflow = create_graph()

    # DB ì—°ê²° (ì—†ìœ¼ë©´ ìžë™ ìƒì„±)
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    with SqliteSaver.from_conn_string(DB_PATH) as memory:
        graph = workflow.compile(checkpointer=memory)
        config = {"configurable": {"thread_id": "standard_loop_1"}}

        print("Type your request (or 'quit'):\n")
        while True:
            try:
                user_input = input("You: ").strip()
                if user_input.lower() in ("q", "quit", "exit"):
                    break
                if not user_input:
                    continue

                for event in graph.stream(
                    {"messages": [HumanMessage(content=user_input)]}, config=config
                ):
                    for node, values in event.items():
                        # Supervisor decision or Agent Final Output
                        if "messages" in values:
                            msg = values["messages"][-1]
                            sender = msg.name if hasattr(msg, "name") else node
                            print(f"\n> [{sender}]: {msg.content[:300]}...")

            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"Error: {e}")


if __name__ == "__main__":
    main()
